{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Variable\n",
    "\n",
    "### 1. Problem Understanding\n",
    "\n",
    "-   What is the problem you are trying to solve\n",
    "\n",
    "    Having a model/dataset that can support multiple variables not just 1. \n",
    "\n",
    "-   What kind of data are you working with?\n",
    "\n",
    "    Numerical and gaussian distribution data that is linear. And matrix instead of an array.\n",
    "\n",
    "-   What are the goals and objectives of the project?\n",
    "\n",
    "    To compute gradient descent that can support multiple variables.\n",
    "    \n",
    "-   What is the expected output of the machine learning algorithm?\n",
    "\n",
    "    Two numbers, w and b optimized\n",
    "\n",
    "-   What are the constraints and limitations of the problem?\n",
    "\n",
    "    None?\n",
    "\n",
    "### 2. Equation\n",
    "\n",
    "\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`\n",
    "\n",
    "\n",
    "\n",
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n",
    "\n",
    "### 3. Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y = np.array([460, 232, 178])\n",
    "\n",
    "\n",
    "b = 785.1811367994083\n",
    "w = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "\n",
    "\n",
    "def compute_cost(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0.0\n",
    "    \n",
    "    f_wb = np.dot(x, w) + b\n",
    "    cost = (f_wb - y) ** 2\n",
    "    total_cost = (1/(2*m)) * np.sum(cost)\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def compute_gradient(x,y,w,b):\n",
    "    #f_wb = np.dot(x,w) + b\n",
    "\n",
    "    m,n = x.shape\n",
    "    print(\"m=\", m)\n",
    "    print(\"n\", n)\n",
    "\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.\n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "        error = (np.dot(x[i],w) + b) - y[i]\n",
    "        dj_dw = error * x[i]\n",
    "        print(\"x[i]=\",error * x[i])\n",
    "        # for j in range(n):\n",
    "        #     dj_dw[j] = dj_dw[j] + error * x[i,j]\n",
    "        dj_db = dj_db + error\n",
    "    \n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "\n",
    "    # dj_dw = (1/m) * np.sum((f_wb - y) * x)\n",
    "    # dj_db = (1/n) * np.sum(f_wb - y)\n",
    "\n",
    "    return dj_db, dj_dw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m= 3\n",
      "n 4\n",
      "x[i]= [-5.00876505e-03 -1.19029588e-05 -2.38059175e-06 -1.07126629e-04]\n",
      "x[i]= [-2.30891812e-03 -4.89177569e-06 -3.26118379e-06 -6.52236758e-05]\n",
      "x[i]= [-8.61024264e-04 -2.02118372e-06 -1.01059186e-06 -3.53707151e-05]\n",
      "dj_db at initial w,b: -1.673925169143331e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.87008088e-04 -6.73727906e-07 -3.36863953e-07 -1.17902384e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(x, y, w, b)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y = np.array([460, 232, 178])\n",
    "\n",
    "\n",
    "b = 785.1811367994083\n",
    "w = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "\n",
    "\n",
    "def compute_cost(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0.0\n",
    "    \n",
    "    f_wb = np.dot(x, w) + b\n",
    "    cost = (f_wb - y) ** 2\n",
    "    total_cost = (1/(2*m)) * np.sum(cost)\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def compute_gradient(x,y,w,b):\n",
    "    #f_wb = np.dot(x,w) + b\n",
    "\n",
    "    m,n = x.shape\n",
    "    print(\"m=\", m)\n",
    "    print(\"n\", n)\n",
    "\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.\n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "        error = (np.dot(x[i],w) + b) - y[i]\n",
    "        print(\"error=\", error)\n",
    "        # dj_dw = error * x[i]\n",
    "        # print(dj_dw)\n",
    "        print(\"x[i]=\", x[i])\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + error * x[i,j]\n",
    "            print(dj_dw[j])\n",
    "        #print(dj_dw)\n",
    "        dj_db = dj_db + error\n",
    "    \n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "\n",
    "    # dj_dw = (1/m) * np.sum((f_wb - y) * x)\n",
    "    # dj_db = (1/n) * np.sum(f_wb - y)\n",
    "\n",
    "    return dj_db, dj_dw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m= 3\n",
      "n 4\n",
      "error= -2.3805917521713127e-06\n",
      "x[i]= [2104    5    1   45]\n",
      "-0.005008765046568442\n",
      "-1.1902958760856563e-05\n",
      "-2.3805917521713127e-06\n",
      "-0.00010712662884770907\n",
      "error= -1.6305918961734278e-06\n",
      "x[i]= [1416    3    2   40]\n",
      "-0.007317683171550016\n",
      "-1.6794734449376847e-05\n",
      "-5.641775544518168e-06\n",
      "-0.00017235030469464618\n",
      "error= -1.0105918590852525e-06\n",
      "x[i]= [852   2   1  35]\n",
      "-0.00817870743549065\n",
      "-1.8815918167547352e-05\n",
      "-6.652367403603421e-06\n",
      "-0.00020772101976263002\n",
      "dj_db at initial w,b: -1.673925169143331e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.72623581e-03 -6.27197272e-06 -2.21745580e-06 -6.92403399e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(x, y, w, b)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3306876842.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[129], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    n 4\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
