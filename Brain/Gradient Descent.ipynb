{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "### 1. Problem Understanding\n",
    "\n",
    "-   What is the problem you are trying to solve\n",
    "\n",
    "    Finding and optimazing w and b using gradient descent. By finding the most optimal values for w and b we can have a better fitting model.\n",
    "\n",
    "-   What kind of data are you working with?\n",
    "\n",
    "    Numerical and gaussian distribution data that is linear\n",
    "\n",
    "-   What are the goals and objectives of the project?\n",
    "\n",
    "    To find the most optimal values that will yield the less cost\n",
    "    \n",
    "-   What is the expected output of the machine learning algorithm?\n",
    "\n",
    "    Two numbers, w and b optimized\n",
    "\n",
    "-   What are the constraints and limitations of the problem?\n",
    "\n",
    "    None?\n",
    "\n",
    "### 2. Equation\n",
    "\n",
    "\n",
    "In lecture, *gradient descent* was described as:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously.  \n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters.\n",
    "\n",
    "### 3. Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(w,b) found by gradient descent: ( 98.6395,-141.4966)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = np.array([2,5,8,10])\n",
    "y = np.array([100,300,600,900])\n",
    "m = len(x)\n",
    "w = 0\n",
    "b = 0\n",
    "\n",
    "def compute_cost(x,y,w,b):\n",
    "    m = len(x)\n",
    "    f_wb = w * x + b\n",
    "    cost =  (f_wb - y) ** 2\n",
    "    total_cost = (1/(2*m)) * np.sum(cost)\n",
    "    return total_cost\n",
    "\n",
    "def compute_gradient(x,y,w,b):\n",
    "    f_wb = w * x + b\n",
    "    dj_dw = (1/m) * np.sum((f_wb - y) * x)\n",
    "    dj_db = (1/m) * np.sum(f_wb - y)\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "compute_gradient(x,y,w,b)\n",
    "\n",
    "\n",
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function): \n",
    "\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(x,y,w,b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(x,y,w,b))\n",
    "            p_history.append([w,b])\n",
    "\n",
    "    return w, b, J_history, p_history\n",
    "\n",
    "\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "iterations = 10000\n",
    "tmp_alpha = 1.0e-2\n",
    "\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x,y,w_init, b_init, tmp_alpha, iterations, compute_cost,compute_gradient)\n",
    "\n",
    "print(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1241.4965986394564"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(x,y,w_final, b_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
